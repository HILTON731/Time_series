{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set accuracy: 1.000\n",
      "Test Set accuracy: 0.937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Train Set accuracy: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Test Set accuracy: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set accuracy: 0.988\n",
      "Test Set accuracy: 0.951\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train Set accuracy: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Test Set accuracy: {:.3f}\".format(tree.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    ({'level': 'Senior', 'lang': 'Java', 'tweets': 'no', 'phd': 'no'}, False),\n",
    "    ({'level': 'Senior', 'lang': 'Java', 'tweets': 'no', 'phd': 'yes'}, False),\n",
    "    ({'level': 'Mid', 'lang': 'Python', 'tweets': 'no', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'Python', 'tweets': 'no', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'R', 'tweets': 'yes', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'R', 'tweets': 'yes', 'phd': 'yes'}, False),\n",
    "    ({'level': 'Mid', 'lang': 'R', 'tweets': 'yes', 'phd': 'yes'}, True),\n",
    "    ({'level': 'Senior', 'lang': 'Python', 'tweets': 'no', 'phd': 'no'}, False),\n",
    "    ({'level': 'Senior', 'lang': 'R', 'tweets': 'yes', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'Python', 'tweets': 'yes', 'phd': 'no'}, True),\n",
    "    ({'level': 'Senior', 'lang': 'Python', 'tweets': 'yes', 'phd': 'yes'}, True),\n",
    "    ({'level': 'Mid', 'lang': 'Python', 'tweets': 'no', 'phd': 'yes'}, True),\n",
    "    ({'level': 'Mid', 'lang': 'Java', 'tweets': 'yes', 'phd': 'no'}, True),\n",
    "    ({'level': 'Junior', 'lang': 'Python', 'tweets': 'no', 'phd': 'yes'}, False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def entropy(class_probabilites):\n",
    "    # 클래스에 속할 확률을 입력하면 엔트로피 계산\n",
    "    # 확률이 0인 경우는 제외함\n",
    "    return sum(-p * math.log(p, 2) for p in class_probabilites if p is not 0)\n",
    "\n",
    "def class_probabilities(labels):\n",
    "    # 레이블의 총 개수 계산 : ex) 5\n",
    "    total_count = len(labels)\n",
    "    # Counter(labels) = {Class0 : 3, Class1 : 2}\n",
    "    # class0 prob = 0.6, class1 prob = 0.4 반환\n",
    "    return [float(count) / float(total_count) for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    # 데이터를 받아서 레이블 정보만 뺀 뒤 리스트로 저장\n",
    "    # ex) labels = [0, 0, 0, 1, 1]\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    # 클래스 비율 계산\n",
    "    probabilities = class_probabilities(labels)\n",
    "    # 클래스 비율을 토대로 엔트로피 계산\n",
    "    return entropy(probabilities)\n",
    "\n",
    "def partition_entropy(subsets):\n",
    "    # subset은 레이블이 있는 데이터의 list의 list\n",
    "    # 그에 대한 엔트로피를 계산한 뒤 모든 subset의 엔트로피 합친 값 반환\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    # subset A의 엔트로피는 A 요소별 엔트로피의 합 * A의 영역 비율\n",
    "    return sum(data_entropy(subset) * len(subset) / total_count for subset in subsets)\n",
    "\n",
    "def partition_by(inputs, attribute):\n",
    "    # attribute 기준으로 inputs를 부분 집합으로 분리\n",
    "    # attribute 변수 내에 3개 값이 있다면 그룹수 = 3\n",
    "    # ex) level 기준 = Senior, Mid, Junior 3개 그룹\n",
    "    groups = defaultdict(list)\n",
    "    for input in inputs:\n",
    "        # 특정 attribute의 값을 불러옴\n",
    "        key = input[0][attribute]\n",
    "        # 이 input을 올바른 list에 추가\n",
    "        groups[key].append(input)\n",
    "    return groups\n",
    "\n",
    "def partition_entropy_by(inputs, attribute):\n",
    "    # 주어진 파티션에 대응되는 엔트로피를 계산\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    return partition_entropy(partitions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def build_tree(inputs, split_candidates=None):\n",
    "    # 첫 분기라면 입력 데이터의 모든 변수가 분기 후보\n",
    "    if split_candidates is None:\n",
    "        # 'lang', 'tweets', 'phd', 'level' 모두 후보\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "\n",
    "    # 입력 데이터에서 범주별 개수를 세어 본다\n",
    "    num_inputs = len(inputs)\n",
    "    num_class0 = len([label for _, label in inputs if label])\n",
    "    num_class1 = num_inputs - num_class0\n",
    "\n",
    "    # class0(true)이 하나도 없으면 False leaf 반환\n",
    "    if num_class0 == 0: return False\n",
    "    # class1(false)이 하나도 없으면 Ture leaf 반환\n",
    "    if num_class1 == 0: return True\n",
    "\n",
    "    # 파티션 기준으로 사용할 변수가 없다면\n",
    "    if not split_candidates:\n",
    "        # 다수결로 결정\n",
    "        # class0(true)가 많으면 true,\n",
    "        # class1(false)가 많으면 false 반환\n",
    "        return num_class0 >= num_class1\n",
    "\n",
    "    # 아니면 가장 적합한 변수를 기준으로 분기\n",
    "    best_attribute = min(split_candidates,\n",
    "                         key=partial(partition_entropy_by, inputs))\n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates\n",
    "                      if a != best_attribute]\n",
    "\n",
    "    # 재귀적으로 서브트리를 구축\n",
    "    subtrees = { attribute_value : build_tree(subset, new_candidates)\n",
    "                 for attribute_value, subset in partitions.items()}\n",
    "    # 기본값\n",
    "    subtrees[None] = num_class0 > num_class1 \n",
    "    return (best_attribute, subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, input):\n",
    "    # 주어진 tree를 기준으로 input을 분류\n",
    "    # 잎 노드이면 값 반환\n",
    "    if tree in [True, False]:\n",
    "        return tree\n",
    "\n",
    "    # 그게 아니면 데이터의 변수로 분기\n",
    "    # 키로 변수값, 값으로 서브트리를 나타내는 dict 사용\n",
    "    attribute, subtree_dict = tree\n",
    "\n",
    "    # 만약 입력된 데이터 변수 가운데 하나가\n",
    "    # 기존에 관찰되지 않았다면 None\n",
    "    subtree_key = input.get(attribute)\n",
    "\n",
    "    # 키에 해당하는 서브트리가 존재하지 않을 때\n",
    "    if subtree_key not in subtree_dict:\n",
    "        # None 서브트리를 사용\n",
    "        subtree_key = None\n",
    "\n",
    "    # 적절한 서브트리를 선택\n",
    "    subtree = subtree_dict[subtree_key]\n",
    "    # 그리고 입력된 데이터를 분류\n",
    "    return classify(subtree, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(inputs)\n",
    "print(classify(tree,\n",
    "        { \"level\" : \"Junior\",\n",
    "          \"lang\" : \"Java\",\n",
    "          \"tweets\" : \"yes\",\n",
    "          \"phd\" : \"no\"} )) # -> True\n",
    "print(classify(tree,\n",
    "        { \"level\" : \"Junior\",\n",
    "          \"lang\" : \"Java\",\n",
    "          \"tweets\" : \"yes\",\n",
    "          \"phd\" : \"yes\"} )) # -> False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Score1 : 1.00\n",
      "Test Set Score1 : 0.94\n",
      "Train Set Score2 : 0.98\n",
      "Test Sect SCore2: 0.94\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\tony9\\Anaconda3\\envs\\timeSeries35\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32mC:\\Users\\tony9\\Anaconda3\\envs\\timeSeries35\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32mC:\\Users\\tony9\\Anaconda3\\envs\\timeSeries35\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    675\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tony9\\Anaconda3\\envs\\timeSeries35\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    958\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d0e3b910a956>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decisionTree1.dot'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decisionTree1.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\tony9\\Anaconda3\\envs\\timeSeries35\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(path, f, prog, encoding)\u001b[0m\n\u001b[0;32m   1732\u001b[0m                 self.write(\n\u001b[0;32m   1733\u001b[0m                     \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1734\u001b[1;33m                     encoding=encoding)\n\u001b[0m\u001b[0;32m   1735\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'write_{fmt}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tony9\\Anaconda3\\envs\\timeSeries35\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, path, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1815\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tony9\\Anaconda3\\envs\\timeSeries35\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1920\u001b[0m                 args[1] = '\"{prog}\" not found in path.'.format(\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pydot\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "dTreeAll = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "dTreeAll.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train Set Score1 : {:.2f}\".format(dTreeAll.score(X_train, y_train)))\n",
    "print(\"Test Set Score1 : {:.2f}\".format(dTreeAll.score(X_test, y_test)))\n",
    "\n",
    "dTreeLimit = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "dTreeLimit.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train Set Score2 : {:.2f}\".format(dTreeLimit.score(X_train, y_train)))\n",
    "print(\"Test Sect SCore2: {:.2f}\".format(dTreeLimit.score(X_test, y_test)))\n",
    "\n",
    "export_graphviz(dTreeLimit, out_file=\"decisionTree1.dot\", class_names=[\"malignant\", \"benign\"],\n",
    "               feature_names=cancer.feature_names, impurity=False, filled=True)\n",
    "\n",
    "(graph,) = pydot.graph_from_dot_file('decisionTree1.dot',encoding='utf8')\n",
    "\n",
    "graph.write_png('decisionTree1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.6 64-bit ('timeSeries35': conda)",
   "language": "python",
   "name": "python35664bittimeseries35condaf09b3f7070e847a1b49e62959b05bf5a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
